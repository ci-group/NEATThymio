\author{Andrea Jemmett, Chiel Kooijman}
\title{Evolving Behaviour for Thymio Robots using NEAT}
% XXX: Include interest-invoking words as real-time, online, etc
\documentclass{article}
\usepackage{graphicx,amsmath}

\begin{document}
	\maketitle
	\begin{abstract}
		We made robots do cool things.
		% FIXME: Make the abstract less abstract.
	\end{abstract}

	\section{Introduction} % {{{
	\label{sec:Introduction}
	In the field of Evolutionary Robotics (ER), several papers have been
	published over the last decades, but most were either concerned
	with evolving a robot controller in a virtual environment
	\cite{silva2015case, simoes1999evolutionary, sims1994evolving}, or more
	recently about evolving neural networks for behaviour on real robots, but
	only succesfully for limited tasks \cite{heinermanevolution,
	watson1999embodied}. In this paper we explore how more complex behaviour
	can be evolved on real robots using (Hyper?)NEAT \cite{stanley2002evolving}
	and using the right processing of input data. As far as the authors are
	aware this is the first time NEAT has been used to evolve behaviour on
	physical robots.
	% TODO: Something about energy and taking inspiration from life and RL?
	% TODO: and we show how we do impossibly amazing things and are much better
	% at everything than everyone else ever.
	In the next section we cover previous work on ER and NEAT. In section
	\ref{sec:method} we give a precise description on the hardware used, we
	explain the Obstacle Avoidance and Foraging tasks, including the reward
	model, the envorinment in which the robots were evaluated, and the
	algorithm and settings used for the experiments.
	In sections \ref{sec:setup} and \ref{sec:results} we cover the exact
	parameters used to run the experiments and their results respectively.
	Conclusions are drawn and further research suggested in the last section.
	% section Introduction }}}

	\section{Related Work} % {{{
	\label{sec:Related Work}
	\cite{heinermanevolution}
	\cite{silva2012odneat}
	\cite{stanley2002evolving, stanley2009hypercube, stanley2006real}
	% section Related Work }}}

	\section{System Description} % {{{
	\label{sec:method}
	\subsection{Robot} % {{{
	\label{sub:Robot}
	The Thymio II robot includes 7 Infra-Red (IR) proximity sensors able detect
	to obstacles of which are 5 in the front and two in the back (values
	between 0 and around 4500, where a higher value corresponds to a near
	obstacle).
	In the foraging task the robot is outfitted with a Raspberry Pi Camera
	Module, which streams 320x240 pixel images, and a piece of velcro with
	which it can grab the pucks. The camera is placed so that it can still see
	the puck when it has stuck to it while seeing as far forward as possible.
	The robot can move through two differential wheels, meaning that two
	different speeds (range between -300 and 300 for obstacle avoidance and
	-150 to 250 for foraging) can be set for each wheel. For the purpose of our
	research, we extend the standard setup with a more powerful logic board,
	wireless communication, and a high capacity battery. We use a Raspberry Pi
	B+ (credit card-sized single-board computer developed in the UK by the
	Raspberry Pi Foundation) that interacts with the Thymio sensors and
	actuators. A WiFi dongle (Edimax 150Mbps Wireless 802.11b/g/n nano USB WiFi
	Adapter model EW-7811Un) attached to the Raspberry Pi ensures communication
	between the robots. The power is given by a Verbatim Dual USB 12000 mAh
	battery that allows for a total experimental time of 10 hours.
	% FIXME maybe not copy this verbatim?
	% subsection Robot }}}

	\subsection{Environment} % {{{
	\label{sub:Environment}
	The robots operate in an arena of two meters by two and a half meters with
	inner and outer walls that act as obstacles to avoid.
	In the foraging task one of the corners of the arena is blue with white
	patches to counteract white-balance issues, and there are five green pucks
	with hook and loop fasteners sides placed in the arena.
	% subsection Environment }}}

	\subsection{Obstacle Avoidance} % {{{
	\label{sub:Obstacle Avoidance}
	In this section we present the Obstacle Avoidance task. In this task the
	robots are placed in the environment and have to learn how to avoid its
	outer walls. Each robot is evaluated for a fixed period of time $T$ and its
	performance is measured using a fitness function.

	\paragraph{Inputs} %Â {{{
	\label{par:obstacle_inputs}
	The input vector to the Neural Network controller is coposed by some of the
	proximity IR sensors. We use the three sensor in the front (the outermost 
	and the central one) and the two sensors from the back. The input vector 
	is then augmented with a bias value of $1$.
	% parapgraph obstacle_inputs }}}

	\paragraph{Fitness function} % {{{
	\label{par:obstacle_fitness}
	We use the following performance measure, as in \cite{heinermanevolution}:
	$$f = \sum_{t=0}^{T}{s_{trans} (1 - s_{rot}) (1 - v_{sens})}$$
	where:
	\begin{itemize}
		\item $s_{trans}$ is the translational speed (non normalized)
			computed as the sum of the right motor speed and the left one;
		\item $s_{rot}$ is the rotational speed, computed as the absolute
			difference between the speed values of the two motors and normalized
			in the range $[0, 1]$;
		\item $v_{sens}$ is the value of the proximity sensor closest to an
			obstacle normalized between 0 and 1.
	\end{itemize}
	The aim of this fitness function is to have a robot capable of going as much
	as possible in a straight path (hence the use of $s_{rot}$), with the
	highest possible speed (hence $s_{trans}$) and without going into walls. The
	component $v_{sens}$ is necessary: suppose that the robot is travelling
	along a straight path at maximum velocity against a wall; without the
	$v_{sens}$ component the robot's performance in this case would be maximal.
	By using $v_{sens}$ we prevent this situation and the fitness score will be
	low.
	% paragraph obstacle_fitness }}}
	% subsection Obstacle Avoidance }}}

	\subsection{Foraging} % {{{
	\label{sub:Foraging}
	In the foraging task the goal is to bring pucks to the goal area using the
	camera as often as possible within its evaluation time.

	\paragraph{Inputs} % {{{
	\label{par:foraging_inputs}
	Inputs consist of the distance and angle from the bottom centre of the image
	to the closest pixel that shows the puck and the goal, and a binary flag
	representing whether the robot has the puck. We first apply a Gaussian filter
	to the camera image, then we convert it from \textit{BGR} to \textit{HSV}
	colour space and we apply a thresholding operator to get two binary images:
	one for the pucks and the other for the goal. The puck distance and angle is
	then the distance from the bottom centre of the image to the closest point
	in the binary image. In a similar manner we compute distance and angle of
	the goal. For performance reasons those values have been precomputed and
	stored in two matrices, one for distances and one for angles.
	The evolved Neural Network is recurrent, meaning that a node is not limited
	to be linked to a node in the next layer (as in feed-forward NN) but can be
	linked also to a node in the previous or same layer.
	% paragraph foraging_inputs }}}

	\paragraph{Fitness function} %{{{
	\label{par:foraging_fitness}
	Each robot has a virtual energy level (which it is not aware of). At the
	beginning of the evaluation, the energy level is set to $INITIAL\_ENERGY$.
	Then, at each successive time step and energy delta is computed and
	subtracted from the energy level. The energy gets decremented by a quantity
	$ENERGY\_DECAY$ every time step and the following formula holds:
	
	$$
	f=
	\begin{cases}
		something & ifrobothaspuck \\
		something\_else & {otherwise}
	\end{cases}
	$$
	% paragraph foraging_fitness }}}

	\begin{itemize}
		\item inputs (dist, angle) for (puck, goal) and has\_puck
		\item energy
		\item fitness
		\item foraging parameters: MIN\_GOAL\_DIST, DECAYS, MAX\_STEPS
	\end{itemize}
	% xXX image: picture of robot + lego contraption
	% subsection Foraging }}}

	% section System Description }}}

	\section{Experimental Setup} % {{{
	\label{sec:setup}

	% section Experimental Setup }}}

	\section{Experimental Results} % {{{
	\label{sec:results}
	
	% section results }}}

	\section{Conclusion and Further Work} % {{{
	\label{sec:conclusion}
	Using energy helps limit evaluation time which makes evolving behaviour on
	physical robots more viable.
	% TODO: use experiments to show that this is actually true
	Calculating something akin to distance and angle is possible in real time.
	Limiting the number of input nodes makes learning faster. % TODO does it?

	Due to the time it took to process the camera input, we had to decrease the
	locomotion speed of the robot so that it had enough time to stop turning
	once it saw the goal or the puck. With a faster processor or dedicated GPU
	image processing time could be decreased, thus allowing us to increase the
	maximum motor speeds, allowing us to evaluate the individuals more quickly.
	Furthermore using more robots in a distributed way such as odNEAT
	\cite{silva2012odneat} would decrease the time needed to evolve robots able
	to evolve fitter robots faster.

	Alternatively, Reinforcement Learning (RL) methods such as DQN
	\cite{mnih2013playing} may be more suitable for this type of task, as they
	allow the behaviour to be adapted at every time-step in a way that is more
	likely to result in better fitness than random mutations.
	% section conclusion }}}

\bibliographystyle{abbrv}
\bibliography{references}
\end{document}
